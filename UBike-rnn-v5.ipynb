{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7106821,"sourceType":"datasetVersion","datasetId":4097269},{"sourceId":7107818,"sourceType":"datasetVersion","datasetId":4097960},{"sourceId":7111750,"sourceType":"datasetVersion","datasetId":4100724},{"sourceId":7112592,"sourceType":"datasetVersion","datasetId":4101363}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport csv\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/dataset-filled/dataset_filled'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-03T15:10:35.306583Z","iopub.execute_input":"2023-12-03T15:10:35.306939Z","iopub.status.idle":"2023-12-03T15:10:35.705375Z","shell.execute_reply.started":"2023-12-03T15:10:35.306911Z","shell.execute_reply":"2023-12-03T15:10:35.704245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Libraries\nimport torch\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom torch.autograd import Variable\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:35.707716Z","iopub.execute_input":"2023-12-03T15:10:35.708249Z","iopub.status.idle":"2023-12-03T15:10:39.832909Z","shell.execute_reply.started":"2023-12-03T15:10:35.708209Z","shell.execute_reply":"2023-12-03T15:10:39.831976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(dataset, lookback):\n    \"\"\"Transform a time series into a prediction dataset\n    \n    Args:\n        dataset: A numpy array of time series, first dimension is the time steps\n        lookback: Size of window for prediction\n    \"\"\"\n    X, y = [], []\n    for i in range(len(dataset)-lookback):\n        feature = dataset[i:i+lookback]\n        target = dataset[i+1:i+lookback+1]\n        X.append(feature)\n        y.append(target)\n    return torch.tensor(X), torch.tensor(y)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:39.834153Z","iopub.execute_input":"2023-12-03T15:10:39.834612Z","iopub.status.idle":"2023-12-03T15:10:39.842391Z","shell.execute_reply.started":"2023-12-03T15:10:39.834581Z","shell.execute_reply":"2023-12-03T15:10:39.841071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_valid_split(timeseries):\n    # train-valid split with 10/2~11/16 [0:2734], 11/17~11/30[2734:]\n    # 10/2 ~ 10/11 [:711]\n    train_size = 2734\n    valid_size = len(timeseries) - train_size\n    train, valid = timeseries[:train_size], timeseries[train_size:]\n    print(len(train), len(valid))\n    # window size approximately = 3 days\n    lookback = 72 * 3\n    X_train, y_train = create_dataset(train, lookback=lookback)\n    X_valid, y_valid = create_dataset(valid, lookback=lookback)\n    # X_test, y_test = create_dataset(test, lookback=lookback)\n    print(X_train.shape, y_train.shape)\n    print(X_valid.shape, y_valid.shape)\n    return X_train, y_train, X_valid, y_valid","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:39.845691Z","iopub.execute_input":"2023-12-03T15:10:39.846092Z","iopub.status.idle":"2023-12-03T15:10:39.858862Z","shell.execute_reply.started":"2023-12-03T15:10:39.846056Z","shell.execute_reply":"2023-12-03T15:10:39.857961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build a basic RNN model","metadata":{}},{"cell_type":"code","source":"class UBIikeRNN(nn.Module):\n    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n        super().__init__()\n        self.hidden_dim = hidden_dim\n        self.layer_dim = layer_dim\n        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, dropout=0.15, batch_first=True)    \n        # Readout layer\n        self.fc = nn.Linear(hidden_dim, output_dim)\n        self.sig = nn.Sigmoid()\n        \n    def forward(self, x):\n        # Initialize hidden state with zeros\n        # h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n#         print(x.size(0)) # x.size(0) = batch size\n        hidden = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).to(device)\n        x = x.view(len(x),1,-1)\n#         print(x.shape)\n        # Passing in the input and hidden state into the model and obtaining outputs\n        out, hidden = self.rnn(x, hidden)\n        \n        # Reshaping the outputs such that it can be fit into the fully connected layer\n        out = out.contiguous().view(-1, self.hidden_dim)\n        out = self.fc(out)\n        out = self.sig(out)\n        return out\n    \n    \n#     def __init__(self):\n#         super().__init__()\n#         self.lstm = nn.LSTM(input_size=1, hidden_size=50, num_layers=1, batch_first=True)\n#         self.linear = nn.Linear(50, 1)\n#     def forward(self, x):\n#         x, _ = self.lstm(x)\n#         x = self.linear(x)\n#         return x","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:39.860057Z","iopub.execute_input":"2023-12-03T15:10:39.860391Z","iopub.status.idle":"2023-12-03T15:10:39.877250Z","shell.execute_reply.started":"2023-12-03T15:10:39.860363Z","shell.execute_reply":"2023-12-03T15:10:39.876183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loss function","metadata":{}},{"cell_type":"code","source":"def getLoss(pred, label):\n    loss = torch.mean(3 * torch.abs(pred-label) * (torch.abs(pred-1/3) + torch.abs(pred-2/3)))\n#     print(f\"loss = {loss}\")\n    return loss","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:39.878417Z","iopub.execute_input":"2023-12-03T15:10:39.878732Z","iopub.status.idle":"2023-12-03T15:10:39.891992Z","shell.execute_reply.started":"2023-12-03T15:10:39.878666Z","shell.execute_reply":"2023-12-03T15:10:39.890930Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Configurations","metadata":{}},{"cell_type":"code","source":"config = {\n    \"batch_size\": 32,\n    \"data_filepath\": '/kaggle/input/stop001-sorted/500101001_sorted.csv',\n    \"inference_filepath\": '/kaggle/input/stop001-1204-1210-inf/stop001_inf_1204_to_1210.csv',\n    \"epochs\": 500,\n    \"learning_rate\": 1e-4,\n    \"weight_decay\": 5e-3,\n    \"save_dir\": \"/kaggle/working/\",\n    \"model_name\": \"stop001-RNN-v1.ckpt\",\n    \"early_stop\": 100,\n}\n# model parameters\ninput_dim = 216\nhidden_dim = 50   # the hidden dim\nlayer_dim = 3   # the number of hidden layers\noutput_dim = 216\ndrop_prob = 0.15\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:39.893244Z","iopub.execute_input":"2023-12-03T15:10:39.893602Z","iopub.status.idle":"2023-12-03T15:10:39.928546Z","shell.execute_reply.started":"2023-12-03T15:10:39.893570Z","shell.execute_reply":"2023-12-03T15:10:39.927552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start Training!!!","metadata":{}},{"cell_type":"code","source":"def train(model, config, train_loader, valid_loader, device):\n    optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay']) \n    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n\n    n_epochs, best_loss, step, early_stop_count = config['epochs'], 10000, 0, 0\n    for epoch in range(n_epochs):\n        model.train() # Set your model to train mode.\n        loss_record = []\n\n        # tqdm is a package to visualize your training progress.\n#         train_pbar = tqdm(train_loader, position=0, leave=True)\n\n        for x, y in train_loader:\n            optimizer.zero_grad()               # Set gradient to zero.\n            x, y = x.to(device), y.to(device)   # Move your data to device. \n            pred = model(x) \n            loss = getLoss(pred, y)\n            loss.backward()                     # Compute gradient(backpropagation).\n            optimizer.step()                    # Update parameters.\n            step += 1\n            loss_record.append(loss.detach().item())\n            \n            # Display current epoch number and loss on tqdm progress bar.\n#             train_pbar.set_description(f'Epoch [{epoch+1}/{n_epochs}]')\n#             train_pbar.set_postfix({'loss': loss.detach().item()})\n#             print(f'Epoch [{epoch+1}/{n_epochs}]')\n#             print(f\"loss: {loss.detach().item()}\")\n\n        mean_train_loss = sum(loss_record)/len(loss_record)\n\n        model.eval() # Set your model to evaluation mode.\n        loss_record = []\n        for x, y in valid_loader:\n            x, y = x.to(device), y.to(device)\n            with torch.no_grad():\n                pred = model(x)\n                loss = getLoss(pred, y)\n\n            loss_record.append(loss.item())\n            \n        mean_valid_loss = sum(loss_record)/len(loss_record)\n        # Note that step should be called after validate()\n        scheduler.step(mean_valid_loss)\n        if mean_valid_loss < best_loss:\n            best_loss = mean_valid_loss\n            torch.save(model.state_dict(), config['save_dir'] + config['model_name']) # Save your best model\n            if(epoch % 10 == 0):\n                print('Saving model with loss {:.3f}...'.format(best_loss))\n            early_stop_count = 0\n        else: \n            early_stop_count += 1\n            \n        if(epoch % 10 == 0):\n            print(f'Epoch [{epoch+1}/{n_epochs}]: Train loss: {mean_train_loss:.4f}, Valid loss: {mean_valid_loss:.4f}')\n        # writer.add_scalar('Loss/valid', mean_valid_loss, step)\n\n            if early_stop_count >= config['early_stop']:\n                print('\\nModel is not improving, so we halt the training session.')\n                print('best loss {:.3f}...'.format(best_loss))\n                return","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:39.930053Z","iopub.execute_input":"2023-12-03T15:10:39.930758Z","iopub.status.idle":"2023-12-03T15:10:39.958478Z","shell.execute_reply.started":"2023-12-03T15:10:39.930698Z","shell.execute_reply":"2023-12-03T15:10:39.957427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference part","metadata":{}},{"cell_type":"code","source":"def predict(timeseries, test_loader, model, device, output_path):\n    model.eval() # Set your model to evaluation mode.\n    preds = []\n    tots = []\n    titles = []\n\n    window_size = 72 * 3\n    test = timeseries[-window_size:].tolist()\n\n\n#     for i in range(future):\n#         seq = torch.FloatTensor(preds[-window_size:])\n#         with torch.no_grad():\n#             model.hidden = (torch.zeros(1,1,model.hidden_size),\n#                             torch.zeros(1,1,model.hidden_size))\n#             preds.append(model(seq).item())\n#     preds[window_size:]\n    i=0\n    for month,day,weekday,hr,mins,lat,lng,act, tot, title in test_loader:\n#         print(i)\n        i+=1\n        tot = tot.tolist()\n        title = list(title)\n#         x = valid[-window_size:].tolist() + x\n#         print(len(test), day)\n        x = torch.FloatTensor(test[-window_size:])\n        x = x.view(-1,len(x))\n#         print(x)\n        x = x.to(device)      \n        tots = tots + tot\n        titles = titles + title\n        with torch.no_grad():  \n#             model.hidden = (torch.zeros(1,1,model.hidden_dim),\n#                             torch.zeros(1,1,model.hidden_dim))\n            pred = model(x)  \n#             print(pred.tolist()[-1][-1])\n            test.append(pred.tolist()[-1][-1])\n            preds.append(pred.detach().cpu())\n            \n#     print(test[window_size:])\n#     preds = torch.cat(preds, dim=0).numpy().tolist()\n    preds = test[window_size:]\n    print(len(preds), len(tots), len(titles))\n#     print(preds[0])\n    plt.plot(preds)\n    plt.show()\n    assert len(preds) == len(tots)\n    assert len(tots) == len(titles)\n    prediction = [['id','sbi']]\n    for (pred, tot, title) in zip(preds, tots, titles):\n        \n        prediction.append([title, pred*tot])\n    \n    with open(output_path, 'w', newline='') as file:\n    # Step 4: Using csv.writer to write the list to the CSV file\n        writer = csv.writer(file)\n        writer.writerows(prediction) # Use writerows for nested list\n    \n    return","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:39.959977Z","iopub.execute_input":"2023-12-03T15:10:39.960369Z","iopub.status.idle":"2023-12-03T15:10:39.975261Z","shell.execute_reply.started":"2023-12-03T15:10:39.960332Z","shell.execute_reply":"2023-12-03T15:10:39.974381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize input dataset\n# Iterate through 112 stops\ni=0\nfor dirname, _, filenames in os.walk('/kaggle/input/dataset-filled/dataset_filled'):\n    for filename in filenames:\n        stop = filename.split('.')[0]\n        config[\"model_name\"] = \"stop\" + stop + \"-RNN-v1.ckpt\"\n        output_path = 'rnn_prediction' + stop + '.csv'\n        print(\"Start training stop \" + stop + \"\\n\")\n        df = pd.read_csv('/kaggle/input/dataset-filled/dataset_filled/' + filename)\n        df_inf = pd.read_csv(\"/kaggle/input/stop001-1204-1210-inf/stop001_inf_1204_to_1210.csv\")\n        # print(len(df['ratio']))\n        # print(df['ratio'][:50])\n        timeseries = df['ratio'].values.astype('float32') \n        X_train, y_train, X_valid, y_valid = train_valid_split(timeseries)\n        train_loader = DataLoader(TensorDataset(X_train, y_train), shuffle=True, batch_size=config['batch_size'])\n        valid_loader = DataLoader(TensorDataset(X_valid, y_valid), shuffle=True, batch_size=config['batch_size'])\n        print(train_loader, valid_loader)\n        model = UBIikeRNN(input_dim=input_dim, hidden_dim=hidden_dim, layer_dim=layer_dim, output_dim=output_dim).to(device)\n        train(model, config, train_loader, valid_loader, device)\n        print(\"Start predicting stop \" + stop + \"\\n\")\n        test_data = df_inf.values.tolist()\n        print(len(test_data))\n        test_loader = DataLoader(test_data, shuffle=False, batch_size=1)\n        print(len(test_loader))\n        predict(timeseries, test_loader, model, device, output_path)\n        print(\"Finish predicting stop \" + stop + \"\\n\")\n        i+=1\n        print(f\"Prgress {i}/112\\n\")\n# plt.plot(timeseries)\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-12-03T15:10:39.978254Z","iopub.execute_input":"2023-12-03T15:10:39.978640Z","iopub.status.idle":"2023-12-03T15:12:45.970286Z","shell.execute_reply.started":"2023-12-03T15:10:39.978607Z","shell.execute_reply":"2023-12-03T15:12:45.969216Z"},"trusted":true},"execution_count":null,"outputs":[]}]}